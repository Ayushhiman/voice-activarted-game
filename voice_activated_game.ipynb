{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time demo - trigger word detection\n",
    "\n",
    "**\"Activate\"** is the trigger word trained for the model.\n",
    "For alternative trigger word, you need to re-train the model to recognize it. More detail refer to [Trigger word detection - v1.ipynb](./Trigger word detection - v1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "from td_utils import *\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keyboard\n",
    "# To generate wav file from np array.\n",
    "from scipy.io.wavfile import write\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 1101 for 2sec input audio\n",
    "Tx = 5511 # The number of time steps input to the model from the spectrogram\n",
    "n_freq = 101 # Number of frequencies input to the model at each time step of the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 272 for 2sec input audio\n",
    "Ty = 1375# The number of time steps in the output of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./models/tr_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_cascade = cv2.CascadeClassifier('rpalm.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect trigger word functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword_spectrum(x,model):\n",
    "    \"\"\"\n",
    "    Function to predict the location of the trigger word.\n",
    "    \n",
    "    Argument:\n",
    "    x -- spectrum of shape (freqs, Tx)\n",
    "    i.e. (Number of frequencies, The number time steps)\n",
    "\n",
    "    Returns:\n",
    "    predictions -- flattened numpy array to shape (number of output time steps)\n",
    "    \"\"\"\n",
    "    # the spectogram outputs  and we want (Tx, freqs) to input into the model\n",
    "    x  = x.swapaxes(0,1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    predictions = model.predict(x)\n",
    "    return predictions.reshape(-1)\n",
    "\n",
    "def has_new_triggerword(predictions, chunk_duration, feed_duration, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Function to detect new trigger word in the latest chunk of input audio.\n",
    "    It is looking for the rising edge of the predictions data belongs to the\n",
    "    last/latest chunk.\n",
    "    \n",
    "    Argument:\n",
    "    predictions -- predicted labels from model\n",
    "    chunk_duration -- time in second of a chunk\n",
    "    feed_duration -- time in second of the input to model\n",
    "    threshold -- threshold for probability above a certain to be considered positive\n",
    "\n",
    "    Returns:\n",
    "    True if new trigger word detected in the latest chunk\n",
    "    \"\"\"\n",
    "    predictions = predictions > threshold\n",
    "    chunk_predictions_samples = int(len(predictions) * chunk_duration / feed_duration)\n",
    "    chunk_predictions = predictions[-chunk_predictions_samples:]\n",
    "    level = chunk_predictions[0]\n",
    "    for pred in chunk_predictions:\n",
    "        if pred > level:\n",
    "            return True\n",
    "        else:\n",
    "            level = pred\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record audio stream from mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_duration = 1 # Each read length in seconds from mic.\n",
    "fs = 44100 # sampling rate for mic\n",
    "chunk_samples = int(fs * chunk_duration) # Each read length in number of samples.\n",
    "\n",
    "# Each model input data duration in seconds, need to be an integer numbers of chunk_duration\n",
    "feed_duration = 10\n",
    "feed_samples = int(fs * feed_duration)\n",
    "\n",
    "assert feed_duration/chunk_duration == int(feed_duration/chunk_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    }
   ],
   "source": [
    "def get_spectrogram(data):\n",
    "    \"\"\"\n",
    "    Function to compute a spectrogram.\n",
    "    \n",
    "    Argument:\n",
    "    predictions -- one channel / dual channel audio data as numpy array\n",
    "\n",
    "    Returns:\n",
    "    pxx -- spectrogram, 2-D array, columns are the periodograms of successive segments.\n",
    "    \"\"\"\n",
    "    nfft = 200 # Length of each window segment\n",
    "    fs = 8000 # Sampling frequencies\n",
    "    noverlap = 120 # Overlap between windows\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, _, _ = mlab.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, _, _ = mlab.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    }
   ],
   "source": [
    "def plt_spectrogram(data):\n",
    "    \"\"\"\n",
    "    Function to compute and plot a spectrogram.\n",
    "    \n",
    "    Argument:\n",
    "    predictions -- one channel / dual channel audio data as numpy array\n",
    "\n",
    "    Returns:\n",
    "    pxx -- spectrogram, 2-D array, columns are the periodograms of successive segments.\n",
    "    \"\"\"\n",
    "    nfft = 200 # Length of each window segment\n",
    "    fs = 8000 # Sampling frequencies\n",
    "    noverlap = 120 # Overlap between windows\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, _, _, _ = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, _, _, _ = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    }
   ],
   "source": [
    "def get_audio_input_stream(callback):\n",
    "    stream = pyaudio.PyAudio().open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=fs,\n",
    "        input=True,\n",
    "        frames_per_buffer=chunk_samples,\n",
    "        input_device_index=0,\n",
    "        stream_callback=callback)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---.1-..-----..1"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "# Queue to communiate between the audio callback and main thread\n",
    "q = Queue()\n",
    "activate=False\n",
    "deactivate=False\n",
    "run = True\n",
    "\n",
    "silence_threshold =500\n",
    "\n",
    "# Run the demo for a timeout seconds\n",
    "timeout = time.time() + 60\n",
    "\n",
    "# Data buffer for the input wavform\n",
    "data = np.zeros(feed_samples, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    if np.abs(data0).mean() < silence_threshold:\n",
    "        sys.stdout.write('-')\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > feed_samples:\n",
    "        data = data[-feed_samples:]\n",
    "        # Process data async by sending a queue.\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = get_audio_input_stream(callback)\n",
    "stream.start_stream()\n",
    "\n",
    "def sound():\n",
    "    try:\n",
    "        model = load_model('./models/tr_model.h5')\n",
    "        global run,stream,activate,deactivate\n",
    "        while run:\n",
    "            data = q.get()\n",
    "            spectrum = get_spectrogram(data)\n",
    "            preds = detect_triggerword_spectrum(spectrum,model)\n",
    "            new_trigger = has_new_triggerword(preds, chunk_duration, feed_duration)\n",
    "            if new_trigger:\n",
    "                keyboard.press_and_release('Alt+Tab')\n",
    "                keyboard.press_and_release('Alt+Tab')\n",
    "                if activate==True:\n",
    "                    deactivate=True\n",
    "                sys.stdout.write('1')\n",
    "                activate=True\n",
    "                if deactivate==True:\n",
    "                    break\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        timeout = time.time()\n",
    "        run = False\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "t1 = Thread(target=sound,args=())\n",
    "t1.start()\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    if activate:\n",
    "        ret, img = cap.read()\n",
    "        img=cv2.resize(img,(1200,800))\n",
    "        img=cv2.flip(img,1)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.rectangle(img, (0,400), (400, 800), (0,0,255), 4)\n",
    "        cv2.putText(img,'Break',(0,400), font, 2,(0,0,255),4)\n",
    "        cv2.rectangle(img, (800, 400), (1200, 800), (0,0,255), 4) \n",
    "        cv2.putText(img,'Gas',(800,400), font, 2,(0,0,255),4)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        break_box=gray[400:800,0:400]\n",
    "        acc_box=gray[400:800,800:1200]\n",
    "        acc_box=cv2.flip(acc_box,1)\n",
    "        break_true = len(hand_cascade.detectMultiScale(break_box, 1.1, 2))>0\n",
    "        acc_true = len(hand_cascade.detectMultiScale(acc_box, 1.1, 2))>0\n",
    "        if break_true:\n",
    "            cv2.rectangle(img, (0,400), (400, 800), (0,255,0), 4)\n",
    "            cv2.putText(img,'Break',(0,400), font, 2,(0,255,0),4)\n",
    "            keyboard.press('Left Arrow')\n",
    "        else:\n",
    "            keyboard.release('Left Arrow')\n",
    "        if acc_true:\n",
    "            cv2.rectangle(img, (800,400), (1200, 800), (0,255,0), 4)\n",
    "            cv2.putText(img,'Gas',(800,400), font, 2,(0,255,0),4)\n",
    "            keyboard.press('Right Arrow')\n",
    "        else:\n",
    "            keyboard.release('Right Arrow')\n",
    "        img=cv2.resize(img,(400,300))\n",
    "        cv2.imshow('game',img)\n",
    "    if(cv2.waitKey(10) & 0xFF == ord('q')):\n",
    "        break\n",
    "    if deactivate:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop_stream()\n",
    "stream.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
